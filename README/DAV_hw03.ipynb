{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3"
      ],
      "metadata": {
        "id": "dXukcikoMQwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Description"
      ],
      "metadata": {
        "id": "8MTBhRPAMpyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we implement and test the Gaussian discriminant analysis, as\n",
        "described in Sec 9.2 in Murphy's book. The project can be broken into three tasks\n",
        "(1) Generate the data points for all classes $c\\in\\{0,1,2,..,C\\}$, and compute\n",
        "the approximations $\\mu_c$ and $\\sigma_c$ that are based on the data points. Also,\n",
        "generate a second set of points, with known tlabels, hat will be used to test\n",
        "the classification function.\n",
        "(2) Evaluate the multivariate Gaussian distribution on the test points of all\n",
        "classes to obtain the probabilities p(X = tjY = c), where t runs through\n",
        "all test points and c runs through all classes.\n",
        "(3) Compute the probabilities p(Y = cjX = t) on the test points using Bayes'\n",
        "formula and for every test point find the value of c with the maximal prob-\n",
        "ability.\n",
        "In your implementation, you should write a separate subroutine for each task. These\n",
        "routines should be written such that they can be used for any dimension D and\n",
        "any number of classes C.\n",
        "You should first experiment with artificially generated data. To that end, use the\n",
        "numpy routine numpy.random.multivariate_normal that generates points ran-\n",
        "domly by the multivariate Gauss distribution. In that case, the subroutine for task\n",
        "1 has an interface as follows\n",
        "#\n",
        "- Parameters\n",
        "- mean center of the Gaussian\n",
        "- cov covariance matrix\n",
        "- nx number data points\n",
        "- nt number test points\n",
        "- Returns\n",
        "- x set of random vectors of length nx (data points)\n",
        "- t set of random vectors of length nt (test points)\n",
        "- mu mean based on x\n",
        "- Sgm covariance matrix based on x\n",
        "\n",
        "\n",
        "#\n",
        "def getArtificialData(mean, cov, nx, nt):\n",
        "\n",
        "Note that this routine calls the random.multivariate_normal twice, i.e., for the\n",
        "data and test set. The vector mean and the matrix cov must be in $R^D$ and $R^{D\\times D}$.\n",
        "The returned values mu and Sgm are computed by (9.19) and (9.20) in Murphy's\n",
        "book. They should be similar to mean and cov, but are different, in general. This\n",
        "routine must be called for each class c. To get the test points of each class into one\n",
        "long vector use the numpy.concatenate function.\n",
        "\n",
        "\\\\\n",
        "\n",
        "The interface for the second task should look like this\n",
        "#\n",
        "- Parameters\n",
        "- t points: t[n,d] is the d-th component of the n-th point\n",
        "- mu mean\n",
        "- Sgm covariance matrix\n",
        "- Returns\n",
        "- p p[n] is the probability density function at the n-th point\n",
        "def evaluateMultiVarGauss(t, mu, Sgm):\n",
        "This routine must be called for each class c with the same merged test points t .\n",
        "\n",
        "\\\\\n",
        "\n",
        "\n",
        "The interface for the third task should look like this\n",
        "#\n",
        "- Parameters\n",
        "- t coordinates of the test points: t[n,d]\n",
        "- pXY conditional probabilities: pXY[n,c]\n",
        "- yEx exact labels of the test points: y[n]\n",
        "\n",
        "def calculateTestSet(t, pXY, yEx: int):\n",
        "\n",
        "Here pXY is a matrix whose columns are the output of evaluateMultiVarGauss.\n",
        "This routine should also print the probabilities and the actual and computed labels\n",
        "for each test point. It should also count the number of mislabelled points."
      ],
      "metadata": {
        "id": "YsYouWNbM6eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test your routines generate three classes with the following parameters\n",
        "\n",
        "\\begin{eqnarray}\n",
        "mean = \\begin{bmatrix}\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix},  \n",
        "cov = \\begin{bmatrix}\n",
        "2 & 1\\\\\n",
        "1 & 50\n",
        "\\end{bmatrix}, nx = 40, nt = 10\n",
        "\\end{eqnarray}\n",
        "\n",
        "\\begin{eqnarray}\n",
        "mean = \\begin{bmatrix}\n",
        "7\\\\\n",
        "5\n",
        "\\end{bmatrix},  \n",
        "cov = \\begin{bmatrix}\n",
        "3 & 1\\\\\n",
        "1 & 3\n",
        "\\end{bmatrix}, nx = 80, nt = 20\n",
        "\\end{eqnarray}\n",
        "\n",
        "\\begin{eqnarray}\n",
        "mean = \\begin{bmatrix}\n",
        "-5\\\\\n",
        "5\n",
        "\\end{bmatrix},  \n",
        "cov = \\begin{bmatrix}\n",
        "5 & 2\\\\\n",
        "2 & 3\n",
        "\\end{bmatrix}, nx = 20, nt = 5\n",
        "\\end{eqnarray}"
      ],
      "metadata": {
        "id": "r-0oYumUPZvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "vgu1j730MiFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code as described above. This will generate quadratic decision\n",
        "boundaries. This should give a very small number of misclassified test\n",
        "points."
      ],
      "metadata": {
        "id": "nw2jGKi3Rqng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "Yh1PcXEsSSAx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy6mr7od_0aM",
        "outputId": "87cbcac0-5176-4120-8ff7-c67e517f0a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified points: 0\n",
            "Actual labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2.]\n",
            "Predicted labels: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
            "Probabilities: [[6.77402820e-03 5.25888994e-04 1.18218903e-06]\n",
            " [5.15573488e-03 1.38885165e-13 1.01159996e-04]\n",
            " [8.37237555e-03 3.13890385e-06 1.18381784e-13]\n",
            " [3.86260383e-03 1.43010897e-14 5.96795302e-28]\n",
            " [1.01583279e-02 1.61418050e-07 1.69129296e-04]\n",
            " [1.13990065e-02 1.94711128e-06 3.22357444e-11]\n",
            " [8.95125488e-03 1.77527815e-04 5.20515556e-06]\n",
            " [5.10033717e-03 4.11071859e-10 1.39346260e-04]\n",
            " [9.48723177e-03 9.55687402e-07 1.06533165e-13]\n",
            " [2.03791119e-03 1.95288151e-18 2.37518976e-32]\n",
            " [8.28838793e-08 2.99843686e-02 2.24909554e-12]\n",
            " [1.29885714e-05 3.53386062e-02 9.14014354e-13]\n",
            " [2.28791324e-06 1.35935555e-02 6.57434189e-10]\n",
            " [7.93612964e-09 2.35856917e-02 1.92929996e-14]\n",
            " [5.86124305e-06 3.34874429e-02 2.29719729e-13]\n",
            " [1.61183537e-06 1.96672328e-02 7.08372737e-15]\n",
            " [7.98496046e-05 2.65882736e-02 9.47185961e-12]\n",
            " [1.41892917e-05 5.04990564e-02 1.50416475e-10]\n",
            " [2.56037738e-04 2.14106914e-02 1.67770503e-10]\n",
            " [1.53497556e-06 1.37839789e-03 3.41389567e-18]\n",
            " [1.37454710e-07 3.68657768e-02 3.87993243e-14]\n",
            " [1.38701819e-06 6.65903360e-03 1.97888793e-16]\n",
            " [1.62927871e-05 3.98923310e-02 6.35452527e-10]\n",
            " [4.17662095e-08 1.01359788e-02 1.00246666e-16]\n",
            " [1.16173170e-04 1.47943513e-02 1.72326652e-12]\n",
            " [1.37560096e-10 5.88931666e-03 5.85773423e-17]\n",
            " [3.23609775e-04 1.69518813e-02 9.77318123e-11]\n",
            " [1.27063022e-05 5.37250081e-02 5.62243969e-11]\n",
            " [3.73387015e-10 8.87128144e-03 2.71501086e-16]\n",
            " [4.88180660e-07 4.16912864e-02 9.90293271e-14]\n",
            " [4.90155895e-03 1.62180330e-11 1.73214617e-02]\n",
            " [6.66974451e-05 1.11319961e-19 1.95405733e-02]\n",
            " [2.28356165e-03 2.24103910e-12 2.93770715e-02]\n",
            " [5.47604156e-05 1.43020509e-20 1.12877263e-02]\n",
            " [1.20454046e-04 1.24747011e-16 4.88368955e-02]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def getArtificialData(mean, cov, nx, nt):\n",
        "    x = np.random.multivariate_normal(mean, cov, nx)\n",
        "    t = np.random.multivariate_normal(mean, cov, nt)\n",
        "    mu = np.mean(x, axis=0)\n",
        "    Sgm = np.cov(x, rowvar=False)\n",
        "    return x, t, mu, Sgm\n",
        "\n",
        "def evaluateMultiVarGauss(t, mu, Sgm):\n",
        "    d = len(mu)\n",
        "    det_Sgm = np.linalg.det(Sgm)\n",
        "    inv_Sgm = np.linalg.inv(Sgm)\n",
        "    p = np.zeros(len(t))\n",
        "    for i in range(len(t)):\n",
        "        diff = t[i] - mu\n",
        "        p[i] = np.exp(-0.5 * np.dot(np.dot(diff, inv_Sgm), diff)) / np.sqrt((2*np.pi)**d * det_Sgm)\n",
        "    return p\n",
        "\n",
        "def calculateTestSet(t, pXY, yEx):\n",
        "    pred_labels = np.argmax(pXY, axis=1)\n",
        "    misclassified = np.sum(pred_labels != yEx)\n",
        "    print(\"Number of misclassified points:\", misclassified)\n",
        "    print(\"Actual labels:\", yEx)\n",
        "    print(\"Predicted labels:\", pred_labels)\n",
        "    print(\"Probabilities:\", pXY)\n",
        "\n",
        "# Generating artificial data and testing\n",
        "mean1 = np.array([0, 0])\n",
        "cov1 = np.array([[2, 1], [1, 50]])\n",
        "nx1 = 40\n",
        "nt1 = 10\n",
        "\n",
        "mean2 = np.array([7, 5])\n",
        "cov2 = np.array([[3, 1], [1, 3]])\n",
        "nx2 = 80\n",
        "nt2 = 20\n",
        "\n",
        "mean3 = np.array([-5, 5])\n",
        "cov3 = np.array([[5, 2], [2, 3]])\n",
        "nx3 = 20\n",
        "nt3 = 5\n",
        "\n",
        "x1, t1, mu1, Sgm1 = getArtificialData(mean1, cov1, nx1, nt1)\n",
        "x2, t2, mu2, Sgm2 = getArtificialData(mean2, cov2, nx2, nt2)\n",
        "x3, t3, mu3, Sgm3 = getArtificialData(mean3, cov3, nx3, nt3)\n",
        "\n",
        "t_all = np.concatenate((t1, t2, t3))\n",
        "mu_all = [mu1, mu2, mu3]\n",
        "Sgm_all = [Sgm1, Sgm2, Sgm3]\n",
        "\n",
        "pXY_all = np.zeros((len(t_all), 3))\n",
        "for i in range(3):\n",
        "    pXY_all[:, i] = evaluateMultiVarGauss(t_all, mu_all[i], Sgm_all[i])\n",
        "\n",
        "yEx_all = np.concatenate((np.zeros(len(t1)), np.ones(len(t2)), np.full(len(t3), 2)))\n",
        "\n",
        "calculateTestSet(t_all, pXY_all, yEx_all)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "FzyyXb5ESW4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the code to test tied covariances (i.e., linear decision boundaries).\n",
        "You can compute the tied covariance matrix by the formula\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\hat{\\Sigma} = \\frac{1}{N}\\sum_{c}N_c\\hat{\\Sigma_{c}}\n",
        "\\end{eqnarray}\n",
        "\n",
        "then you can re-use all previously written routines. Run the code with the\n",
        "same data as before and compare the number of misclassified points with\n",
        "the result you got in (1)."
      ],
      "metadata": {
        "id": "mTZuM978SZuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "7MrH7TwfVacv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def getArtificialData(mean, cov, nx, nt):\n",
        "    x = np.random.multivariate_normal(mean, cov, nx)\n",
        "    t = np.random.multivariate_normal(mean, cov, nt)\n",
        "    mu = np.mean(x, axis=0)\n",
        "    Sgm = np.cov(x, rowvar=False)\n",
        "    return x, t, mu, Sgm\n",
        "\n",
        "def calculateTiedCovariance(data):\n",
        "    N = len(data)\n",
        "    mu = np.mean(data, axis=0)\n",
        "    Sgm_tied = np.zeros((len(mu), len(mu)))  # Initialize tied covariance matrix\n",
        "    for x in data:\n",
        "        diff = x - mu\n",
        "        Sgm_tied += np.outer(diff, diff)\n",
        "    Sgm_tied /= N\n",
        "    return Sgm_tied\n",
        "\n",
        "def evaluateMultiVarGauss(t, mu, Sgm):\n",
        "    d = len(mu)\n",
        "    det_Sgm = np.linalg.det(Sgm)\n",
        "    inv_Sgm = np.linalg.inv(Sgm)\n",
        "    p = np.zeros(len(t))\n",
        "    for i in range(len(t)):\n",
        "        diff = t[i] - mu\n",
        "        p[i] = np.exp(-0.5 * np.dot(np.dot(diff, inv_Sgm), diff)) / np.sqrt((2*np.pi)**d * det_Sgm)\n",
        "    return p\n",
        "\n",
        "def calculateTestSet(t, pXY, yEx):\n",
        "    pred_labels = np.argmax(pXY, axis=1)\n",
        "    misclassified = np.sum(pred_labels != yEx)\n",
        "    print(\"Number of misclassified points:\", misclassified)\n",
        "    print(\"Actual labels:\", yEx)\n",
        "    print(\"Predicted labels:\", pred_labels)\n",
        "    print(\"Probabilities:\", pXY)\n",
        "\n",
        "# Generating artificial data and testing\n",
        "mean1 = np.array([0, 0])\n",
        "cov1 = np.array([[2, 1], [1, 50]])\n",
        "nx1 = 40\n",
        "nt1 = 10\n",
        "\n",
        "mean2 = np.array([7, 5])\n",
        "cov2 = np.array([[3, 1], [1, 3]])\n",
        "nx2 = 80\n",
        "nt2 = 20\n",
        "\n",
        "mean3 = np.array([-5, 5])\n",
        "cov3 = np.array([[5, 2], [2, 3]])\n",
        "nx3 = 20\n",
        "nt3 = 5\n",
        "\n",
        "x1, t1, mu1, _ = getArtificialData(mean1, cov1, nx1, nt1)\n",
        "x2, t2, mu2, _ = getArtificialData(mean2, cov2, nx2, nt2)\n",
        "x3, t3, mu3, _ = getArtificialData(mean3, cov3, nx3, nt3)\n",
        "\n",
        "t_all = np.concatenate((t1, t2, t3))\n",
        "mu_all = [mu1, mu2, mu3]\n",
        "x_all = [x1, x2, x3]\n",
        "\n",
        "# Calculate tied covariance matrix\n",
        "Sgm_tied = calculateTiedCovariance(np.concatenate(x_all))\n",
        "\n",
        "pXY_all = np.zeros((len(t_all), 3))\n",
        "for i in range(3):\n",
        "    pXY_all[:, i] = evaluateMultiVarGauss(t_all, mu_all[i], Sgm_tied)\n",
        "\n",
        "yEx_all = np.concatenate((np.zeros(len(t1)), np.ones(len(t2)), np.full(len(t3), 2)))\n",
        "\n",
        "calculateTestSet(t_all, pXY_all, yEx_all)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEtvu_mvBT5d",
        "outputId": "e6e240d0-742c-4976-8acc-ed3af487c8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified points: 2\n",
            "Actual labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2.]\n",
            "Predicted labels: [0 0 0 0 0 0 2 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
            "Probabilities: [[8.76155385e-04 1.20229460e-04 2.71916743e-05]\n",
            " [6.54896207e-03 2.33243450e-03 3.36197513e-03]\n",
            " [4.90538754e-03 2.93283196e-03 3.30998908e-03]\n",
            " [1.68143813e-03 2.83587181e-04 7.46329249e-05]\n",
            " [6.14610296e-05 2.17814884e-06 1.17546294e-06]\n",
            " [5.23385269e-03 2.13106047e-03 4.22839879e-03]\n",
            " [4.53621836e-04 6.71206360e-04 1.35883530e-03]\n",
            " [1.99627048e-03 1.94104169e-04 1.55291401e-04]\n",
            " [2.45852098e-03 2.86736742e-03 2.25642341e-03]\n",
            " [3.77963162e-03 8.11769555e-04 3.22672837e-04]\n",
            " [6.48133569e-04 5.56505633e-03 7.87887339e-05]\n",
            " [1.32580526e-03 6.67263666e-03 1.06343592e-04]\n",
            " [2.24125424e-03 7.06519679e-03 2.69893096e-04]\n",
            " [1.67087613e-03 6.69939826e-03 2.84255643e-04]\n",
            " [3.52850811e-03 6.63282904e-03 5.38414103e-04]\n",
            " [1.84424462e-03 7.03052730e-03 2.19415727e-04]\n",
            " [3.03912657e-03 6.81343780e-03 5.17342442e-04]\n",
            " [6.87034317e-04 4.70392180e-03 2.22363711e-05]\n",
            " [3.78433120e-04 4.78050460e-03 2.52165013e-05]\n",
            " [2.32221094e-03 6.95817269e-03 3.74076573e-04]\n",
            " [1.62011503e-03 6.69920867e-03 1.22653220e-04]\n",
            " [2.56123075e-03 5.89422354e-03 7.80310731e-04]\n",
            " [3.09002831e-03 6.05532667e-03 2.55884393e-04]\n",
            " [4.89773991e-03 5.20870880e-03 1.41131135e-03]\n",
            " [1.22051560e-03 5.96751068e-03 2.57984898e-04]\n",
            " [2.07656076e-03 5.83649363e-03 6.25762804e-04]\n",
            " [2.37089376e-03 6.00678225e-03 6.82895007e-04]\n",
            " [1.24668932e-03 6.54416012e-03 1.75266531e-04]\n",
            " [1.29809026e-03 6.71749830e-03 1.15198556e-04]\n",
            " [1.64652401e-03 6.60863749e-03 1.17532108e-04]\n",
            " [1.35610345e-03 1.00794872e-04 6.62894383e-03]\n",
            " [3.56113387e-03 3.60865130e-04 6.39928464e-03]\n",
            " [2.00948137e-03 3.47277779e-04 6.72864759e-03]\n",
            " [1.62493247e-03 2.06572238e-04 6.82886559e-03]\n",
            " [4.37246365e-03 7.77673267e-04 6.16606779e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "uEUvKu8GViig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the methodology on the iris data set, that was mentioned in the lecture.\n",
        "You can import it with the following commands\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "the petal/sepal dimensions are in the array iris.data and the correspond-\n",
        "ing labels are in the array iris.target. You will notice that the first 50\n",
        "entries have label 0, followed by 50 entries with label 1 and 50 entries with\n",
        "label 2. Use the first 40 entries in each class as data points and the next\n",
        "10 entries as test points. You have to write a new routine getIrisData()\n",
        "with similar functionality as getArtificialData(). If you have done the\n",
        "implementation of evaluateMultiVarGauss() and calculateTestSet()\n",
        "right, then you will be able to run these routines with the iris data set as\n",
        "well. Again, count the number of misclassified items in the test set."
      ],
      "metadata": {
        "id": "qWguwS33VmV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "l2O8G4OUWGLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without tied covariance"
      ],
      "metadata": {
        "id": "L-By9gAAWJUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "def getIrisData():\n",
        "    iris = load_iris()\n",
        "    data = iris.data\n",
        "    target = iris.target\n",
        "\n",
        "    # Extracting first 40 entries from each class as data points\n",
        "    x1 = data[target == 0][:40]\n",
        "    x2 = data[target == 1][:40]\n",
        "    x3 = data[target == 2][:40]\n",
        "\n",
        "    # Extracting next 10 entries from each class as test points\n",
        "    t1 = data[target == 0][40:50]\n",
        "    t2 = data[target == 1][40:50]\n",
        "    t3 = data[target == 2][40:50]\n",
        "\n",
        "    # Calculate mean and covariance for each class\n",
        "    mu1 = np.mean(x1, axis=0)\n",
        "    mu2 = np.mean(x2, axis=0)\n",
        "    mu3 = np.mean(x3, axis=0)\n",
        "    Sgm1 = np.cov(x1, rowvar=False)\n",
        "    Sgm2 = np.cov(x2, rowvar=False)\n",
        "    Sgm3 = np.cov(x3, rowvar=False)\n",
        "\n",
        "    return [x1, x2, x3], [t1, t2, t3], [mu1, mu2, mu3], [Sgm1, Sgm2, Sgm3]\n",
        "\n",
        "# Function to evaluate multivariate Gaussian distribution\n",
        "def evaluateMultiVarGauss(t, mu, Sgm):\n",
        "    d = len(mu)\n",
        "    det_Sgm = np.linalg.det(Sgm)\n",
        "    inv_Sgm = np.linalg.inv(Sgm)\n",
        "    p = np.zeros(len(t))\n",
        "    for i in range(len(t)):\n",
        "        diff = t[i] - mu\n",
        "        p[i] = np.exp(-0.5 * np.dot(np.dot(diff, inv_Sgm), diff)) / np.sqrt((2*np.pi)**d * det_Sgm)\n",
        "    return p\n",
        "\n",
        "# Function to calculate misclassified points in the test set\n",
        "def calculateTestSet(t, pXY, yEx):\n",
        "    pred_labels = np.argmax(pXY, axis=1)\n",
        "    misclassified = np.sum(pred_labels != yEx)\n",
        "    print(\"Number of misclassified points:\", misclassified)\n",
        "    print(\"Actual labels:\", yEx)\n",
        "    print(\"Predicted labels:\", pred_labels)\n",
        "    print(\"Probabilities:\", pXY)\n",
        "\n",
        "# Get Iris data and test\n",
        "x_all, t_all, mu_all, Sgm_all = getIrisData()\n",
        "\n",
        "# Calculate probabilities for each class\n",
        "pXY_all = np.zeros((len(np.concatenate(t_all)), 3))\n",
        "for i in range(3):\n",
        "    pXY_all[:, i] = evaluateMultiVarGauss(np.concatenate(t_all), mu_all[i], Sgm_all[i])\n",
        "\n",
        "# Set actual labels for test set\n",
        "yEx_all = np.concatenate((np.zeros(len(t_all[0])), np.ones(len(t_all[1])), np.full(len(t_all[2]), 2)))\n",
        "\n",
        "# Calculate and print misclassified points in the test set\n",
        "calculateTestSet(np.concatenate(t_all), pXY_all, yEx_all)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--fSet3bH2UZ",
        "outputId": "2f9ac754-206d-49bf-f6e7-676d9b5d3dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified points: 0\n",
            "Actual labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2.]\n",
            "Predicted labels: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
            "Probabilities: [[7.81435194e+000 5.88902311e-023 9.35547567e-036]\n",
            " [2.93126805e-003 1.73532119e-012 4.79357840e-026]\n",
            " [2.45619345e+000 1.70664995e-019 1.93466684e-029]\n",
            " [4.81174613e-003 3.58520997e-018 6.64854132e-029]\n",
            " [9.87470311e-002 6.31867093e-021 8.39767713e-030]\n",
            " [3.45674864e+000 2.01425700e-016 2.61432439e-029]\n",
            " [3.52940179e+000 4.57657405e-026 8.55244329e-036]\n",
            " [9.29964603e+000 5.79339655e-019 1.29804288e-029]\n",
            " [1.12524756e+001 1.12468803e-025 4.38094192e-038]\n",
            " [1.57261747e+001 9.24900533e-021 1.06527756e-033]\n",
            " [7.13615519e-074 2.40751868e-001 1.31807440e-002]\n",
            " [3.98144515e-086 2.44508165e+000 1.83458137e-002]\n",
            " [8.29902570e-060 3.92526536e+000 3.08060272e-004]\n",
            " [3.39890017e-036 3.67453462e-001 5.59130953e-006]\n",
            " [1.93728765e-069 3.33068754e+000 9.94926107e-003]\n",
            " [2.67930372e-064 4.88100376e-001 6.35497100e-004]\n",
            " [2.96056406e-068 2.71070381e+000 3.38968338e-003]\n",
            " [8.99168518e-072 3.77762450e+000 5.22602840e-004]\n",
            " [1.32502087e-032 9.19610454e-003 3.95785623e-008]\n",
            " [2.18262715e-065 3.97986533e+000 2.33053061e-003]\n",
            " [9.43493717e-192 1.65374215e-008 4.55493468e-001]\n",
            " [1.36864782e-161 1.09930077e-009 5.74628822e-003]\n",
            " [4.47325197e-136 2.04944426e-003 9.08514382e-001]\n",
            " [1.45954928e-197 1.00979403e-005 1.02991327e+000]\n",
            " [6.99204941e-204 2.91398336e-009 3.00237797e-001]\n",
            " [1.91631676e-166 6.38674374e-009 6.81660862e-002]\n",
            " [5.75505316e-133 2.35510388e-004 1.95355696e-001]\n",
            " [1.79928931e-143 4.84677519e-003 9.51533704e-001]\n",
            " [4.95621356e-174 6.35435188e-006 2.59190286e-001]\n",
            " [8.45991244e-128 7.32798211e-002 5.89810146e-001]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With tied covariance"
      ],
      "metadata": {
        "id": "-jAez6J2WRW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "def getIrisData():\n",
        "    iris = load_iris()\n",
        "    data = iris.data\n",
        "    target = iris.target\n",
        "\n",
        "    # Extracting first 40 entries from each class as data points\n",
        "    x1 = data[target == 0][:40]\n",
        "    x2 = data[target == 1][:40]\n",
        "    x3 = data[target == 2][:40]\n",
        "\n",
        "    # Extracting next 10 entries from each class as test points\n",
        "    t1 = data[target == 0][40:50]\n",
        "    t2 = data[target == 1][40:50]\n",
        "    t3 = data[target == 2][40:50]\n",
        "\n",
        "    # Calculate mean and tied covariance for each class\n",
        "    mu1 = np.mean(x1, axis=0)\n",
        "    mu2 = np.mean(x2, axis=0)\n",
        "    mu3 = np.mean(x3, axis=0)\n",
        "    x_all = [x1, x2, x3]\n",
        "\n",
        "    # Calculate tied covariance matrix\n",
        "    Sgm_tied = calculateTiedCovariance(np.concatenate(x_all))\n",
        "\n",
        "    return x_all, [t1, t2, t3], [mu1, mu2, mu3], Sgm_tied\n",
        "\n",
        "# Function to calculate tied covariance matrix\n",
        "def calculateTiedCovariance(data):\n",
        "    N = len(data)\n",
        "    mu = np.mean(data, axis=0)\n",
        "    Sgm_tied = np.zeros_like(np.cov(data.T))\n",
        "    for x in data:\n",
        "        diff = x - mu\n",
        "        Sgm_tied += np.outer(diff, diff)\n",
        "    Sgm_tied /= N\n",
        "    return Sgm_tied\n",
        "\n",
        "# Function to evaluate multivariate Gaussian distribution\n",
        "def evaluateMultiVarGauss(t, mu, Sgm):\n",
        "    d = len(mu)\n",
        "    det_Sgm = np.linalg.det(Sgm)\n",
        "    inv_Sgm = np.linalg.inv(Sgm)\n",
        "    p = np.zeros(len(t))\n",
        "    for i in range(len(t)):\n",
        "        diff = t[i] - mu\n",
        "        p[i] = np.exp(-0.5 * np.dot(np.dot(diff, inv_Sgm), diff)) / np.sqrt((2*np.pi)**d * det_Sgm)\n",
        "    return p\n",
        "\n",
        "# Function to calculate misclassified points in the test set\n",
        "def calculateTestSet(t, pXY, yEx):\n",
        "    pred_labels = np.argmax(pXY, axis=1)\n",
        "    misclassified = np.sum(pred_labels != yEx)\n",
        "    print(\"Number of misclassified points:\", misclassified)\n",
        "    print(\"Actual labels:\", yEx)\n",
        "    print(\"Predicted labels:\", pred_labels)\n",
        "    print(\"Probabilities:\", pXY)\n",
        "\n",
        "# Get Iris data and test\n",
        "x_all, t_all, mu_all, Sgm_tied = getIrisData()\n",
        "\n",
        "# Calculate probabilities for each class\n",
        "pXY_all = np.zeros((len(np.concatenate(t_all)), 3))\n",
        "for i in range(3):\n",
        "    pXY_all[:, i] = evaluateMultiVarGauss(np.concatenate(t_all), mu_all[i], Sgm_tied)\n",
        "\n",
        "# Set actual labels for test set\n",
        "yEx_all = np.concatenate((np.zeros(len(t_all[0])), np.ones(len(t_all[1])), np.full(len(t_all[2]), 2)))\n",
        "\n",
        "# Calculate and print misclassified points in the test set\n",
        "calculateTestSet(np.concatenate(t_all), pXY_all, yEx_all)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdrNVZ2TBnUx",
        "outputId": "f7fe7b65-5508-4523-c3aa-a76c323fcb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified points: 2\n",
            "Actual labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2.]\n",
            "Predicted labels: [0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2]\n",
            "Probabilities: [[4.54916324e-01 6.58986143e-02 2.78920213e-02]\n",
            " [1.24527684e-03 2.63726150e-03 9.69484255e-05]\n",
            " [2.31087777e-01 6.49994770e-02 1.58943673e-02]\n",
            " [1.63846718e-01 2.65905796e-02 2.05158568e-02]\n",
            " [1.46555046e-01 1.63812299e-02 1.66534022e-02]\n",
            " [2.07576164e-01 9.91956534e-02 1.52586758e-02]\n",
            " [1.88975549e-01 1.81641187e-02 1.22466739e-02]\n",
            " [3.58829547e-01 1.10856704e-01 2.46336945e-02]\n",
            " [4.56337852e-01 5.20381657e-02 2.49171085e-02]\n",
            " [5.36601567e-01 1.37075854e-01 3.08747759e-02]\n",
            " [8.06906631e-03 6.96682396e-02 2.25791512e-02]\n",
            " [8.00197241e-02 3.17353188e-01 2.75393593e-01]\n",
            " [7.71178286e-02 5.06940312e-01 1.34417121e-01]\n",
            " [1.61141756e-02 1.23824956e-01 1.62223083e-02]\n",
            " [6.40723862e-02 3.68718217e-01 1.68166660e-01]\n",
            " [4.17196752e-02 1.27147585e-01 8.95389307e-02]\n",
            " [8.72317876e-02 3.21526256e-01 2.18419360e-01]\n",
            " [1.29423080e-01 5.38822062e-01 2.83683942e-01]\n",
            " [1.42510117e-02 5.39326284e-02 1.23324486e-02]\n",
            " [1.14334871e-01 4.90734306e-01 2.63252570e-01]\n",
            " [1.39329293e-03 6.79842870e-03 3.97932073e-02]\n",
            " [3.19240538e-05 1.13129492e-04 4.67650791e-04]\n",
            " [1.49370152e-02 1.37720722e-01 1.93652387e-01]\n",
            " [1.06847189e-02 5.45161978e-02 3.23636021e-01]\n",
            " [7.05125609e-04 2.26750704e-03 2.54646461e-02]\n",
            " [2.11875534e-04 9.97342288e-04 3.69614507e-03]\n",
            " [5.59235079e-03 7.89721437e-02 5.36679756e-02]\n",
            " [2.69133948e-02 1.39061318e-01 3.24320398e-01]\n",
            " [1.40389146e-03 2.95162148e-03 3.59195435e-02]\n",
            " [1.55667658e-02 7.60111598e-02 1.65028673e-01]]\n"
          ]
        }
      ]
    }
  ]
}